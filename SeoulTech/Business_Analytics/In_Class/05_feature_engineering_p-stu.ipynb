{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcfaadc",
   "metadata": {},
   "source": [
    "## [Feature scaling + One hot encoding] for Mixed-Type variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979fa874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mglearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loading dataset\n",
    "adult_path = os.path.join(mglearn.datasets.DATA_PATH, \"adult.data\")\n",
    "data = pd.read_csv(\n",
    "    adult_path, header=None, index_col=False,\n",
    "    names=['age', 'workclass', 'fnlwgt', 'education',  'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "           'income'])\n",
    "\n",
    "# to make the problem simple, select some variables\n",
    "data = data[['age', 'workclass', 'education', 'gender', 'hours-per-week',\n",
    "             'occupation', 'income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "295aba59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass    education   gender  hours-per-week  \\\n",
       "0       39          State-gov    Bachelors     Male              40   \n",
       "1       50   Self-emp-not-inc    Bachelors     Male              13   \n",
       "2       38            Private      HS-grad     Male              40   \n",
       "3       53            Private         11th     Male              40   \n",
       "4       28            Private    Bachelors   Female              40   \n",
       "...    ...                ...          ...      ...             ...   \n",
       "32556   27            Private   Assoc-acdm   Female              38   \n",
       "32557   40            Private      HS-grad     Male              40   \n",
       "32558   58            Private      HS-grad   Female              40   \n",
       "32559   22            Private      HS-grad     Male              20   \n",
       "32560   52       Self-emp-inc      HS-grad   Female              40   \n",
       "\n",
       "               occupation  income  \n",
       "0            Adm-clerical   <=50K  \n",
       "1         Exec-managerial   <=50K  \n",
       "2       Handlers-cleaners   <=50K  \n",
       "3       Handlers-cleaners   <=50K  \n",
       "4          Prof-specialty   <=50K  \n",
       "...                   ...     ...  \n",
       "32556        Tech-support   <=50K  \n",
       "32557   Machine-op-inspct    >50K  \n",
       "32558        Adm-clerical   <=50K  \n",
       "32559        Adm-clerical   <=50K  \n",
       "32560     Exec-managerial    >50K  \n",
       "\n",
       "[32561 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mixed-type variables. \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ddaadc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Private             22696\n",
      " Self-emp-not-inc     2541\n",
      " Local-gov            2093\n",
      " ?                    1836\n",
      " State-gov            1298\n",
      " Self-emp-inc         1116\n",
      " Federal-gov           960\n",
      " Without-pay            14\n",
      " Never-worked            7\n",
      "Name: workclass, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# you can check the distribution of categories in each categorical variable.\n",
    "print(data.workclass.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d447979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prof-specialty       4140\n",
      " Craft-repair         4099\n",
      " Exec-managerial      4066\n",
      " Adm-clerical         3770\n",
      " Sales                3650\n",
      " Other-service        3295\n",
      " Machine-op-inspct    2002\n",
      " ?                    1843\n",
      " Transport-moving     1597\n",
      " Handlers-cleaners    1370\n",
      " Farming-fishing       994\n",
      " Tech-support          928\n",
      " Protective-serv       649\n",
      " Priv-house-serv       149\n",
      " Armed-Forces            9\n",
      "Name: occupation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.occupation.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bedf28d",
   "metadata": {},
   "source": [
    "# Preprocessing 하기\n",
    "\n",
    "We want to apply the following preprocessing : \n",
    "- Standard scaler for numerical variable\n",
    "- One hot encoding for categorical variable   \n",
    "\n",
    "\n",
    "Then, apply Logistic regression to predict the 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a1a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = data.drop(\"income\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data.income, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0974d68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide X_train and X_test into numerical and categorical variables, respectively.\n",
    "# outputs: X_train_cat, X_train_num, X_test_cat, X_test_num\n",
    "'''TODO'''\n",
    "\n",
    "X_train_cat = X_train[['workclass','education','gender','occupation']]\n",
    "X_train_num = X_train[['age','hours-per-week']]\n",
    "\n",
    "X_test_cat = X_test[['workclass','education','gender','occupation']]\n",
    "X_test_num = X_test[['age','hours-per-week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a45f306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For X_train_cat and X_test_cat, apply onehotencoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "'''TODO'''\n",
    "ohe.fit(X_train_cat)\n",
    "\n",
    "X_train_cat_ohe = ohe.transform(X_train_cat)\n",
    "X_test_cat_ohe = ohe.transform(X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2903cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For X_train_num and X_test_num, apply standardscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "'''TODO'''\n",
    "scaler.fit(X_train_num)\n",
    "\n",
    "X_train_num_scaled = scaler.transform(X_train_num)\n",
    "X_test_num_scaled = scaler.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abb840da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate them agin into X_train and X_test. \n",
    "'''TODO'''\n",
    "X_train_trans = np.concatenate([X_train_cat_ohe, X_train_num_scaled], axis = 1)\n",
    "X_test_trans = np.concatenate([X_test_cat_ohe, X_test_num_scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bf8bd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set:  0.808991524382754\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression model and check the accuracy for test set\n",
    "'''TODO'''\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_trans,y_train)\n",
    "\n",
    "y_test_hat = logreg.predict(X_test_trans)\n",
    "\n",
    "print(\"Accuracy on testing set: \", accuracy_score(y_test,y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd69e0",
   "metadata": {},
   "source": [
    "- The ColumnTransformer makes the same task a bit simpler. \n",
    "- How to use it can be intuitively known from the code below. Just check it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cfae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = data.drop(\"income\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data.income, random_state=0)\n",
    "\n",
    "#*****************\n",
    "ct = ColumnTransformer(\n",
    "    [(\"scaling\", StandardScaler(), ['age', 'hours-per-week']),\n",
    "     (\"onehot\", OneHotEncoder(sparse=False), ['workclass', 'education', 'gender', 'occupation'])])\n",
    "\n",
    "ct.fit(X_train)\n",
    "X_train_trans = ct.transform(X_train)\n",
    "#*****************\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_trans, y_train)\n",
    "\n",
    "X_test_trans = ct.transform(X_test)\n",
    "y_test_hat = logreg.predict(X_test_trans)\n",
    "\n",
    "print(\"Accuracy on testing set: \", accuracy_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4464314",
   "metadata": {},
   "source": [
    "---\n",
    "## Simulated example for bias-variance decompostion\n",
    "\n",
    "2주전 수업내용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcebd19e",
   "metadata": {},
   "source": [
    "Let's calculate the bias and variance ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349029fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589844e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test: densely distributed data points between 0 and 2\n",
    "x_test= np.linspace(0,2,1000) # evenly spaced samples between start and stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True function we don't really know\n",
    "def true_function(x):\n",
    "    return np.sin(np.pi * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = true_function(x_test) # we don't know either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f3e6fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let't just see what it looks like. \n",
    "plt.plot(x_test,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f16fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample just 2 data points for training data\n",
    "x_train = np.random.uniform(0,2,2)\n",
    "y_train = true_function(x_train)\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "plt.plot(x_test,y_true)\n",
    "plt.scatter(x_train, y_train, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b012065",
   "metadata": {},
   "source": [
    "#### H0: Constant function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with constant function \n",
    "def constant_function(x_train, y_train, x_test): # it outputs average of y_train regardless of the value of x_test\n",
    "    average_of_train_data = np.mean(y_train)    \n",
    "    return np.repeat(average_of_train_data, len(x_test))\n",
    "\n",
    "# with this constant function, we can make prediction on x_test.\n",
    "y_test = constant_function(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ebf69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x_test, y_true)\n",
    "plt.plot(x_test, y_test)\n",
    "plt.scatter(x_train, y_train, c='r')\n",
    "# orange line is a trained model using H0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a5f9d3",
   "metadata": {},
   "source": [
    "#### H1: Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with linear regression (line passing through the two training data points)\n",
    "reg = LinearRegression().fit(x_train.reshape(-1,1), y_train)\n",
    "y_test = reg.predict(x_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c99ee85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(x_test, y_true)\n",
    "plt.plot(x_test, y_test)\n",
    "plt.scatter(x_train, y_train, c='r')\n",
    "# orange line is a trained model using H1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71897a",
   "metadata": {},
   "source": [
    "#### Repeat for 1000 times and calcualte the bias and variance yourself. (using H1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ea96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using linear regression,\n",
    "# repeat the above procedure [sampling - training - test] for 1000 times. \n",
    "# Don't forget to save all the prediction results(y_test) for all iterations.\n",
    "\n",
    "y_test_list = []\n",
    "for i in range(1000):\n",
    "    '''\n",
    "    TODO\n",
    "    '''\n",
    "#     2개 샘플\n",
    "    x_train = np.random.uniform(0,2,2)\n",
    "    y_train = true_function(x_train)\n",
    "    reg = LinearRegression().fit(x_train.reshape(-1,1), y_train)\n",
    "    y_test = reg.predict(x_test.reshape(-1,1))\n",
    "    \n",
    "    y_test_list.append(y_test)\n",
    "y_test_total = np.stack(y_test_list)\n",
    "\n",
    "\n",
    "y_test_total.shape\n",
    "\n",
    "y_test_avg = y_test_total.mean(axis=0)\n",
    "\n",
    "plt.plot(x_test,y_true)\n",
    "plt.plot(x_test,y_test_avg, c = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee2fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value of bias\n",
    "'''TODO'''\n",
    "bias = np.mean((y_test_avg-y_true)**2)\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7553c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value of variance\n",
    "'''TODO'''\n",
    "variance = np.mean(np.var(y_test_total,axis=0))\n",
    "variance\n",
    "\n",
    "# training sample n이 커지면 variance가 작아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value of test error\n",
    "'''TODO'''\n",
    "error = np.mean((y_test_total-y_true)**2)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0845fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the sum of bias and variance is equal to the test error\n",
    "'''TODO'''\n",
    "bias+variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42e123",
   "metadata": {},
   "source": [
    "- If the model is too simple, the bias is high.\n",
    "- The more complex the model, the higher the variance.\n",
    "- As the amount of training data increases, variance can be lowered.\n",
    "\n",
    "\n",
    "- **This is main reason why we need large amount of training data to achieve a good model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b503ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the experiment again with H0. Check the value of bias and variance.\n",
    "'''TODO'''\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the experiment again with the increased number of training instances. Check the value of bias and variance.\n",
    "'''TODO'''\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
